# Attaque-et-protection-contre-les-deepfakes-audio
📌 Contexte : Avec l’avancée des modèles de synthèse vocale, des attaquants peuvent
usurper des voix pour tromper des systèmes biométriques ou réaliser des fraudes.
Description :
● Générer des deepfakes audio en imitant des voix avec des modèles IA.
● Développer un algorithme de détection basé sur l’analyse des fréquences et des
caractéristiques vocales.
